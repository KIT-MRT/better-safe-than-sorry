% !TeX root = ../root.tex
% -*- root: ../root.tex -*-
\section{Introduction}

\subsection{Motivation}

Behavior planning and decision-making are crucial for robots to operate autonomously in dynamic environments, ensuring to achieve their goals while adapting to changes and uncertainties.
Key to reliable operation in fields like mobile, industrial, or service robotics is ensuring safety and robustness in these processes.

Arbitration graphs, hierarchical behavior models, manage complex decision-making
by allowing integration of diverse methods while ensuring scalability, maintainability, and transparency.
However, real-world complexities challenge the safety and robustness of such systems.

This paper aims to enhance arbitration graph safety and robustness by identifying and handling erroneous or unsafe behavior commands at runtime.

\begin{figure}
    \centering
    \includegraphics[width=0.8\columnwidth]{figures/entt_pacman.png}
    \caption{The Pac-Man simulation used to demonstrate the presented extension to the arbitration graph framework.
    Leveraging the framework's flexibility and scalability,
    we incorporate a verification step and fallback layers
    to ensure robust and safe decision-making.}
    \label{fig:entt-pacman}
\end{figure}

\begin{figure}
    \centering
    \includesvg[width=\columnwidth,inkscapelatex=false]{figures/pacman_arbitrator_base}
    % \includesvg[width=\columnwidth,inkscapelatex=true,pretex=\begin{svgfontonly},apptex=\end{svgfontonly}]{figures/pacman_arbitrator_base}
    \caption{A basic arbitration graph for playing Pac-Man.}
    \label{fig:pacman-arbitrator-base}
\end{figure}

\subsection{State of the art}
Behavioral decision-making includes both monothematic methods and generic architectures.

End-to-end machine learning approaches learn the entire process from sensor data to commands, requiring extensive data and computational power.
Due to their highly integrated nature, it is challenging to interpret or influence the resulting behavior directly.

Traditional architectures like \glspl{FSM} allow situational planning but scale poorly with complexity. Behavior-based methods, derived from Brooks' subsumption architecture, evolved into \glspl{BT}, among others. Popularized by their use in gaming, they are also applied in robotics. These provide a hierarchical decision making structure, offering modularity and responsiveness but becoming cumbersome with extensive conditions.

Arbitration graphs, combining subsumption and object-oriented programming, enhance reusability and system clarity through modularity and functional decomposition. Used in robotic soccer and automated driving, these graphs employ behavior components to interpret situations and plan actions, while arbitrators select the most suitable behaviors.

\subsection{Contributions}

\begin{description}[align=left]
    \item[Verification Logic] We extend the arbitration process to ensure that only verified behaviors are executed.
    \item[Fallback Logic] We introduce fallback options for cases where behavior commands fail verification.
    \item[Application] We validate the safety concept in autonomous driving simulations, demonstrating reduced accident risk and improved safety.
\end{description}
