% !TeX root = ../root.tex
% -*- root: ../root.tex -*-
\section{Introduction}

\subsection{Motivation}

Behavior planning and decision-making are critical components that enable robots to perform tasks autonomously and adaptively in dynamic environments.
These processes involve selecting and executing commands to achieve specific goals while responding to changes and uncertainties in the surroundings.
Ensuring safety and robustness in behavior planning and decision-making is essential for robots to operate reliably and effectively across various applications, such as autonomous driving, industrial automation, and service robotics.

Arbitration graphs, a type of hierarchical behavior model, can be used to manage complex decision-making processes in robots.
The bottom-up architecture makes them very scalable and maintainable while allowing for a very transparent decision-making process.
The modularity of arbitration graphs enables the integration of diverse scenario-specific methods and seamless switching between them.
However, the inherent complexity and dynamic nature of real-world environments pose significant challenges to the safety and robustness of these systems.

Ensuring the safety and robustness of the arbitration graphs governing such decisions is paramount to prevent failures and ensure reliable operation under varying conditions.

This paper focuses on enhancing the safety and robustness of arbitration graphs by identifying and handling erronous or unsafe commands at runtime.

Benefits of the proposed method:
\begin{itemize}
    \item Modular behavioral components in a hierarchical arbitration graph
    \item Scalable in the number of behavioral options
    \item Allows the combination of diverse scenario-specific methods
    \item Robust execution and safe behavior through verification and various fallback levels
    \item Modular and hierarchical structure enables an iterative design process
    \item Increases maintainability and leads to transparent and traceable decision-making
\end{itemize}

\subsection{State of the art}

\subsubsection*{End-to-end learning}
Learn a unified approach for all possible maneuver and trajectory variants \cite{casas_mp3_2021}

\paragraph*{Advantages}
        \begin{itemize}
            \item Consider uncertainties in situation interpretation implicitly
            \item Superior in perception and prediction
        \end{itemize}
\paragraph*{Disadvantages}
        \begin{itemize}
            \item Require enormous amounts of data and powerful computing infrastructure
            \item Limited possibilities to influence system behavior
            \item Difficult to improve specific misbehavior
        \end{itemize}

\subsubsection*{Behavior trees}
Bottom-up design: Compose overall behavior from simple sub-behaviors \cite{brooks_robust_1986}

\paragraph*{Advantages}
        \begin{itemize}
            \item High reactivity
            \item Consistent modularity
            \item Good scalability
            \item Easy to implement
            \item Can combine different behavior planning methods
        \end{itemize}
\paragraph*{Disadvantages}
\begin{itemize}
    \item Can become complex and difficult to understand for large systems
\end{itemize}

\subsubsection*{Arbitration graphs}
Combine subsumption concept with object-oriented programming \cite{lauer_cognitive_2010}
\begin{itemize}
    \item Modular behavioral components address fundamental behavioral competencies
    \item Application-independent arbitrators decide which behavior option is most suitable
    \item High modularity and scalability
    \item Verifiable and robust
\end{itemize}

\subsection{Pac-Man}

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{figures/entt_pacman.png}
    \caption{The Pac-Man implementation used to demonstrate the proposed method.}
    \label{fig:entt-pacman}
\end{figure}
Pac-Man is a classic arcade game released in 1980, where the player controls Pac-Man, a yellow, circular character navigating a maze.
The primary objective is to eat all the dots in the maze while avoiding four ghosts—Blinky, Pinky, Inky, and Clyde—that pursue Pac-Man.
Consuming power pellets temporarily turns the ghosts blue, allowing Pac-Man to eat them for bonus points.
Depicted in Figure \ref{fig:entt-pacman} is an open-source implementation\footnote{github.com/indianakernick/EnTT-Pacman} of the game that we use to demonstrate the proposed method.
We split Pac-Man's behavior into the following behavioral components:

\begin{itemize}
    \item \textbf{Avoid Ghosts:} Pac-Man tries to increase the distance to the ghosts to avoid being eaten.
    \item \textbf{Chase Ghosts:} After consuming a power pellet Pac-Man might try to eat the ghosts for extra points.
    \item \textbf{Eat Dots:} Pac-Man tries to eat all the dots in the maze to win the game.
\end{itemize}

\subsection{Contributions}

\begin{itemize}
    \item \textbf{Verification logic:} The arbitration process is extended by a verification logic that ensures that only behavior options are executed that pass verification. This verification logic is based on three verifiers that check potential maneuvers for validity, feasibility, and traffic safety.
    \item \textbf{Safety concept:} A safety concept is designed to ensure robust and safe behavior arbitration through verification, real-time capability, redundancy, and diversity.
    \item \textbf{Application:} The proposed safety concept is evaluated in an application-oriented simulation environment. The results show that the proposed approach can effectively reduce the risk of accidents and improve the overall safety of automated vehicles.
\end{itemize}
