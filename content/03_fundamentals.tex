% !TeX root = ../root.tex
% -*- root: ../root.tex -*-

\section{Fundamentals}

\todo[inline]{Fix references}

\subsection{Decision-Making}

Decision-making is crucial in a robot's planning module, determining commands based on the current situation.
Methods range from graph-based techniques like A*, PRM*, and RRT* to probabilistic methods and machine learning for implicit decisions.
This work, however, focuses on rule-based methods, such as finite state machines, behavior trees, or arbitration graphs, which address decision making through discrete state or mode transitions.

% Finite State Machines
FSMs, from hardware design and theoretical computer science, represent behavior modes with transitions triggered by events. Despite their simplicity, FSMs scale poorly and are difficult to modify due to extensive transitions.

% Behavior Trees
Behavior trees, initially designed for game development, have been increasingly used in robotics since 2012.
They separate behavior decision-making from execution, forming loop-free undirected graphs.
Internal nodes determine selection mechanisms, while leaves describe behaviors and conditions.
Evaluated at a fixed frequency, nodes return their status as running, completed, or failed.
Control flow nodes decide on further evaluations.

Condition nodes check if their underlying conditions are met without affecting the environment, while action nodes execute behaviors and return their status.
By distinguishing between condition and action nodes, the preconditions of a behavior are decoupled from the actual execution of the behavior.
To design a safe system, these actions must be linked to reliable condition nodes.

Behavior trees generalize many architectures, such as hierarchical finite state machines and decision trees [Col17], excelling in modularity, hierarchical organization, reusability, responsiveness, and interpretability [Col18].
Their flexibility allows reuse of individual behaviors without specifying their relations [Bag12].
The selection mechanism is intuitive and easy to follow during operation.
However, extensive preconditions can make representations unwieldy, and safety depends significantly on node arrangement.
These drawbacks are addressed by arbitration graphs.

% Arbitration Graphs
The concept of behavior arbitration originated in the context of robot soccer, integrating ideas from Brooks' behavior-based subsumption, knowledge-based architectures like Belief-Desire-Intention (BDI), and programming paradigms such as object-oriented programming.
This approach was thoroughly described in [Lau10] and is summarized in the following.

This modular framework is characterized by clear interfaces for transparent decision-making, using atomic behavior modules to represent simple abilities and behaviors.
These modules are combined using arbitrators to create complex system behaviors.

The input to a behavior module is the current situation in the form sensor data or an interpreted environment model.
If its preconditions are met, i.e. the so-called invocation condition is satisfied and the behavior is therefore applicable, the behavior module computes a command.
An active behavior module checks whether all conditions are met to continue the behavior using the commitment condition meaning the calling instance itself does not need any knowledge of the prerequisites for executing a behavior module.

Generic arbitrators combine behavior modules, filtering them using invocation and commitment conditions, and select the best option to execute.
Arbitration schemes include priority-based, completion-based, random, sequence-based, and cost-based.

\subsection{Fault-tolerant/Robust Systems}

In automated systems, both hardware and software issues can compromise performance and safety.
Causes include programming errors and runtime issues such as optimization problems, making error diagnosis and treatment crucial in system design.

Research on reliable and fault-tolerant systems aims to design dependable hardware and software despite potential errors, using metrics like error probability, mean lifespan, failure rate, and availability.
Terminology varies, but disturbances ("faults") can lead to errors, potentially causing system failures.

Reliability measures include error prevention, removal, tolerance, and prediction.
Prevention and removal focus on design and development, while tolerance involves detecting and preventing operational errors.
Prediction estimates future failures.
Error tolerance involves diagnosing and handling errorsâ€”restoring faulty components, computing correct results despite faults, or removing faulty components from the system.

\subsection{Behavior Verification}

Verifying the safety of a command is a challenge in itself only complicated by the fact that it is highly domain-specific.
In the Pac-Man example, a command could be considered safe if it does not lead to a collision with a wall or a ghost.
In real-world applications such as autonomous driving, more sophisticated methods are required to ensure safety.
Here, a common method for behavior verification is the set-based approach with reachable sets analysis.
This approach involves planning a fail-safe trajectory in addition to the intended trajectory.
Worst-case occupancies are used to overapproximate possible behaviors of other traffic participants.
The behavior is considered safe if the fail-safe trajectory does not overlap with worst-case occupancies.
The benefits of this approach include provable safety under specified assumptions.

