% !TeX root = ../root.tex
% -*- root: ../root.tex -*-

\section{Fundamentals}

\todo[inline]{Fix references}

\subsection{Decision-Making}

Decision making is a crucial part of a robot's planning module.
Based on the current situation, it determines a command, trajectory or maneuver to be executed.
Various methods have been established in the literature, ranging from pure decision making to situation-specific trajectory planning.

Rule-based methods, such as finite state machines, behavior trees, or arbitration graphs, address decision making through discrete state or mode transitions.
Graph-based or search-based methods like A*, Probabilistic Roadmaps (PRM*), and Rapidly-exploring Random Trees (RRT*) are popular in path planning for mobile robots but can also be used for decision making.
In trajectory planning, probabilistic methods like Partially Observable Markov Decision Processes (POMDPs) and machine learning techniques, including reinforcement learning, are increasingly employed.
These methods often make implicit decisions, such as when and where to change paths.

This section focuses on rule-based methods, including classical state-based methods like finite state machines, as well as behavior-based methods like behavior trees and arbitration graphs.
For a comprehensive overview of methods, refer to [Sch18, Yur20, Voß21, Gam21], with a more detailed version of this section available in [Orz23].
Rule-based methods are particularly prevalent for prototypes used by smaller research groups due to their ease of application, numerous freely available software frameworks [Sch14, Bur18, Gre21b, The20b], including direct integration with MATLAB [The20a], and their standardization in the Unified Modeling Language [Obj17].

\subsection{Finite State Machines}
Finite state machines (FSMs) originate from hardware design and theoretical computer science [Wag06, Hop07, Vos16].
They are now widely used in robotics [Sic16] and driver assistance systems [Zie14b, Aeb15] due to their simplicity and ease of implementation.
This section provides a practical introduction to FSM theory, summarizing key concepts from [Vos16] and [Hop07].

An FSM consists of:

\begin{itemize}
  \item a finite set of states $S$,
  \item a finite set of input symbols $\Sigma$ (or events),
  \item a finite set of output symbols $\Delta$ (or actions),
  \item a state transition function $\delta: S \times \Sigma \rightarrow S$,
  \item an output function $\lambda: S \rightarrow \Delta$,
  \item an initial state $s_0 \in S$ and
  \item a finite set of final states $F \subseteq S$.
\end{itemize}

The FSM starts in the initial state $s_0$.
Upon receiving an event $e_i \in \Sigma$, it transitions to a new state $s_{i+1} = \delta(s_i, e_i)$, which may be the same as the current state $s_{i+1} = s_i$.
After each transition, the FSM produces an output $a_i = \lambda(s_i)$.
Extensions like hierarchical state machines can contain nested or parallel FSMs.
In robotics, states typically represent behavior modes, with outputs guiding actions to the execution layer.

FSMs are suitable for manageable behavior problems due to their straightforward implementation and intuitive representation.
However, their scalability is limited, as the number of possible transitions grows quadratically with the number of states.
Hierarchical FSMs can mitigate this by organizing states into defined levels.
Another drawback is the poor modifiability: adding or removing states often requires extensive adjustments to existing states and transitions.
FSM transitions resemble jump instructions, making code difficult to understand, analyze, or verify.
Tracking the active state requires a detailed event history, reminiscent of the now-avoided Goto statements in structured programming languages [Dij68, Dah72].
Additionally, visualizing FSMs for complex systems becomes cumbersome due to the numerous transitions.

\subsection{Behavior Trees}

Behavior trees were initially designed in computer game development [Iov22] and have increasingly been used in robotics applications since 2012 [Bag12, Ögr12].
Comprehensive overviews and introductions to behavior trees are provided in [Iov22, Col18].
This section, however, aims to give a brief, practice-oriented introduction to the methodology.

Behavior trees are characterized by a strict functional separation between behavior decision-making and execution.
Formally, they are connected loop-free undirected graphs, where the internal nodes (control flow nodes) determine the selection mechanism, while the leaves describe possible behaviors (action nodes) and conditions (condition nodes).
Starting from the root node, the tree is evaluated at a fixed frequency, similar to a depth-first search.
A node indicates whether it is still running, has completed successfully, or has failed through its return value.
Depending on the return value, the parent control flow node evaluates additional child nodes or returns its own status.
Various types of control flow nodes are available, including sequences, fallback structures, and concurrency.

When a condition node is evaluated, it returns whether the underlying condition is met, without affecting the environment.
Action nodes, on the other hand, execute the corresponding behavior command upon invocation and return the status of that behavior.
Thus, action nodes describe the individual behavior options of a system, while their preconditions are modeled through condition nodes.
By distinguishing between condition and action nodes, the preconditions of a behavior are decoupled from the actual execution of the behavior.
To design a safe system, these actions must be linked to reliable condition nodes.

In summary, behavior trees generalize many other architectures such as hierarchical finite state machines and decision trees [Col17], offering several advantages over them: they excel in modularity, hierarchical organization, reusability of components, responsiveness, and interpretability [Col18].
Compared to finite state machines, their greater flexibility is particularly advantageous.
Individual behaviors can be (re)used within a behavior tree without specifying their relation to other behavior options [Bag12].
The selection mechanism of a behavior tree is also intuitively comprehensible in graphical representation and easy to follow during online operation.
However, in practice, the representation can become extensive, as each precondition is modeled as a separate leaf node.
The system's safety also significantly depends on the arrangement of nodes within the tree due to the aforementioned decoupling of preconditions and behavior execution.
These drawbacks are addressed by the arbitration graphs in the following section.

\subsection*{Arbitration Graphs}

The concept of behavior arbitration originated in the context of robot soccer, integrating ideas from Brooks' behavior-based subsumption, knowledge-based architectures like Belief-Desire-Intention (BDI), and programming paradigms such as object-oriented programming.
This approach was thoroughly described in [Lau10] and is summarized in the following.

Behavior arbitration is a modular framework, characterized by clear interfaces leading to a transparent decision-making process.
The concept relies on atomic behavior modules that represent simple abilities and behaviors.
These modules are combined using arbitrators to create complex system behaviors, from tactics to strategies.
Instead of decomposing a problem top-down into subproblems, complex behavior is iteratively composed bottom-up from simple behavioral competencies.

Behavior modules receive input from the current situation in the form of sensor data or an interpreted environment model and translate this into the behavior's command.
In addition to its actual command, each behavior module determines whether its preconditions are met and the behavior is therefore currently applicable at all using the so-called invocation condition.

If a behavior module is active, it also returns whether all conditions are met to continue the behavior using the commitment condition.
Therefore, the calling instance itself does not need any knowledge of the prerequisites for executing a behavior module.

Generic arbitrators compile a set of behavior modules, referred to as options, into a tactic.
They filter applicable options using the options's invocation and commitment conditions and select the best option as the intention to execute.
Various arbitration schemes can be used, including priority-based, completion-based, random, sequence-based, and cost-based arbitrators.

In the case of Pac-Man a behavior module such as "Avoid Ghost" uses the environment model to determine e.g. the ghost's position to check its own applicability using the invocation and commitment conditions.
If it is applicable, the behavior module will pass a command such as a path or a desired direction to it's parental arbitrator which will decide if this behavior should be executed based on its decision-making policy.
Without knowing its options internals, the arbitrator compiles a complex behavior from the simple behavior modules.

\subsection{Fault-tolerant/Robust Systems}

Fault-tolerant systems are designed to maintain a high level of reliability despite potential faults or errors. In such systems, faults, errors, and failures are distinguished. Measures to increase reliability can be categorized into fault prevention, removal, tolerance, and prediction. Fault tolerance is a key pillar of reliable systems and encompasses fault diagnosis and fault handling. Fault handling methods include error recovery, error passivation, and error compensation.

\subsection{Safe Behaviors}

\subsubsection*{Goal}
The goal of traffic safety is to ensure the absence of unreasonable risks when objects are moved in a (traffic) system.

\todo[inline]{Generalize the following}
\subsubsection*{Behavior Verification}
One of the challenges in traffic safety is verifying the safety of a planned behavior while considering uncertainties. A common method for behavior verification is the set-based approach with reachable sets analysis. This approach involves planning a fail-safe trajectory in addition to the intended trajectory. Worst-case occupancies are used to overapproximate possible behaviors of other traffic participants. The behavior is considered safe if the fail-safe trajectory does not overlap with worst-case occupancies. The benefits of this approach include provable safety under specified assumptions.

\subsubsection*{Overall Safety Approach}
An effective approach to ensuring traffic safety involves:
\begin{itemize}
    \item \textbf{Risk Analysis:} Identify and assess risks throughout the development process.
    \item \textbf{Verification and Validation:} Verify and validate safety at all levels, including hardware, behavior, and fleet.
    \item \textbf{Monitoring:} Continuously monitor risks during operation to ensure ongoing safety.
\end{itemize}
